{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Packages\" data-toc-modified-id=\"Import-Packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Packages</a></span></li><li><span><a href=\"#Attempt-1-to-check-for-new-contact\" data-toc-modified-id=\"Attempt-1-to-check-for-new-contact-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Attempt 1 to check for new contact</a></span></li><li><span><a href=\"#Double-check-contact_check\" data-toc-modified-id=\"Double-check-contact_check-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Double-check contact_check</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python_projects\\thesis\\lib\\site-packages\\thefuzz\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as notebook_tqdm\n",
    "import time\n",
    "\n",
    "os.environ['WDM_LOG'] = '0'\n",
    "os.environ['WDM_LOG_LEVEL'] = '0'\n",
    "\n",
    "from fuzzysearch import find_near_matches\n",
    "from thefuzz import process, fuzz\n",
    "\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#------------ stopword collection----------#\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords_en = en.Defaults.stop_words\n",
    "de = spacy.load('de_core_news_lg')\n",
    "stopwords_de = de.Defaults.stop_words\n",
    "stopwords = stopwords_en.union(stopwords_de)\n",
    "\n",
    "#------------ load custom NER model----------#\n",
    "ner = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory is now D:\\HSLU_Projects\\Thesis\n"
     ]
    }
   ],
   "source": [
    "workdir = 'D:\\HSLU_Projects\\Thesis'\n",
    "if os.getcwd() != workdir:\n",
    "    os.chdir(workdir)\n",
    "    print(f\"Working Directory is now {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Working Directory is already set to {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1 to check for new contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect(r\"D:\\HSLU_projects\\Thesis\\Data\\Contacts.db\")\n",
    "df = pd.read_sql_query(\"SELECT * FROM Contacts\", cnx)\n",
    "cnx.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "        Name Vorname                           Firma  \\\n0   Ademoglu   Amara            Mobimo Management AG   \n1  Aebischer  Thomas    ACUTRONIC Medical Systems AG   \n2  Aeschbach   André      Dialog Verwaltungs-Data AG   \n3     Agotai   Doris                            FHNW   \n4     Albert  Stefan  AMAG Automobil- und Motoren AG   \n\n                              Email  Is_Valid  \n0          amara.ademoglu@mobimo.ch         1  \n1  t.aebischer@acutronic-medical.ch         1  \n2         andre.aeschbach@dialog.ch         1  \n3              doris.agotai@fhnw.ch         1  \n4             stefan.albert@amag.ch         1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Vorname</th>\n      <th>Firma</th>\n      <th>Email</th>\n      <th>Is_Valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ademoglu</td>\n      <td>Amara</td>\n      <td>Mobimo Management AG</td>\n      <td>amara.ademoglu@mobimo.ch</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Aebischer</td>\n      <td>Thomas</td>\n      <td>ACUTRONIC Medical Systems AG</td>\n      <td>t.aebischer@acutronic-medical.ch</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aeschbach</td>\n      <td>André</td>\n      <td>Dialog Verwaltungs-Data AG</td>\n      <td>andre.aeschbach@dialog.ch</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Agotai</td>\n      <td>Doris</td>\n      <td>FHNW</td>\n      <td>doris.agotai@fhnw.ch</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albert</td>\n      <td>Stefan</td>\n      <td>AMAG Automobil- und Motoren AG</td>\n      <td>stefan.albert@amag.ch</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--log-level = 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "        Name Vorname    Firma               Email  Is_Valid\n201  Helling   Felix  Crowdli  helling@crowdli.ch         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Vorname</th>\n      <th>Firma</th>\n      <th>Email</th>\n      <th>Is_Valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>201</th>\n      <td>Helling</td>\n      <td>Felix</td>\n      <td>Crowdli</td>\n      <td>helling@crowdli.ch</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_slice = df.sample(n=1)\n",
    "random_slice"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_replacement_contact(random_slice):\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    driver.implicitly_wait(25)\n",
    "    driver.get(\"https://www.google.com/\")\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                    \"/html/body/div[2]/div[2]/div[3]/span/div/div/div/div[3]/button[2]\"))).click()\n",
    "    except:\n",
    "        pass\n",
    "    m = driver.find_element(by=By.NAME, value=\"q\")\n",
    "    m = driver.find_element(by=By.NAME, value='q')\n",
    "    m.send_keys(random_slice.iloc[0]['Firma'] + \" Head of Communication Switzerland\")\n",
    "    m.send_keys(Keys.RETURN)\n",
    "\n",
    "    first_page = page = driver.find_element(By .TAG_NAME, \"body\").text\n",
    "    if \"featured snippet\" in first_page:\n",
    "        print(\"Featured snippet found, extract team from here\")\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                       '//*[@id=\"rso\"]/div[1]/block-component/div/div[1]/div/div/div/div/div[1]/div/div/div/div/div/div[2]/div/div/div[1]'))).click()\n",
    "            page = driver.find_element(By .TAG_NAME, \"body\").text\n",
    "        except:\n",
    "            print(\"Can't find the element\")\n",
    "            pass\n",
    "    else:\n",
    "        print(\"not found, going to first link\")\n",
    "\n",
    "        try:\n",
    "            check_for_linkedin = driver.find_element(By.XPATH, '//*[@id=\"rso\"]/div[1]').text\n",
    "            print(check_for_linkedin)\n",
    "            if \"https://ch.linkedin.com\" in check_for_linkedin:\n",
    "                print(\"LinkedIn found, extract info from here\")\n",
    "                page = check_for_linkedin\n",
    "            else:\n",
    "                print(\"LinkedIn not found, going to first link\")\n",
    "                WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                        '//*[@id=\"rso\"]/div[1]/div/div[1]/div/a/h3'))).click()\n",
    "                time.sleep(5)\n",
    "                if driver.findElement( By.XPATH, '/html/body/div[4]/div/div/div[2]/div[1]/button' ).size() != 0:\n",
    "                    WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                        '/html/body/div[4]/div/div/div[2]/div[1]/button'))).click()\n",
    "                    page = driver.find_element(By .TAG_NAME, \"body\").text\n",
    "                else:\n",
    "                    page = driver.find_element(By .TAG_NAME, \"body\").text\n",
    "        except:\n",
    "            print(\"Can't find the element\")\n",
    "            pass\n",
    "\n",
    "    driver.close()\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def clean_page(page):\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    cleanup = soup.get_text().strip()\n",
    "    jumble = cleanup.split()\n",
    "    cleaned = ' '.join(jumble).strip()\n",
    "    finish = []\n",
    "    for word in cleaned.split():\n",
    "        if word not in stopwords:\n",
    "            finish.append(word)\n",
    "    final = ' '.join(finish)\n",
    "    tags = ner(final)\n",
    "    print(soup.prettify())\n",
    "    print('-'*50)\n",
    "    print(final)\n",
    "    print('-'*50)\n",
    "    spacy.displacy.render(tags, style=\"ent\", jupyter=True)\n",
    "    print('-'*50)\n",
    "    persons = []\n",
    "    for ent in tags.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            print(ent.text)\n",
    "            persons.append(ent.text)\n",
    "    return persons[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found, going to first link\n",
      "Jens Wiesenhütter – Head of Communications Switzerland\n",
      "https://ch.linkedin.com › jens-wiesen...\n",
      "· Translate this page\n",
      "Sankt Gallen, Schweiz · Head of Communications Switzerland · Helvetia Versicherungen Schweiz\n",
      "Creative communication manager with experience and passion in strategy, social media, databased storytelling, digital marketing, content marketing, ...\n",
      "Missing: Crowdli | Must include: Crowdli\n",
      "\n",
      "Vanessa Von der Muhll – Head of Communications ... - Linkedin\n",
      "https://ch.linkedin.com › vanessavondermuhll\n",
      "Genf, Genf, Schweiz · Head of Communications and Engagement · ISO - International Organization for Standardization\n",
      "Fifteen years' experience (largely internationally) in the field of communications including strategy, marketing, brand, web, social media, press, ...\n",
      "LinkedIn found, extract info from here\n",
      "Jens Wiesenhütter – Head of Communications Switzerland\n",
      "https://ch.linkedin.com › jens-wiesen...\n",
      "· Translate this page\n",
      "Sankt Gallen, Schweiz · Head of Communications Switzerland · Helvetia Versicherungen Schweiz\n",
      "Creative communication manager with experience and passion in strategy, social media, databased storytelling, digital marketing, content marketing, ...\n",
      "Missing: Crowdli | Must include: Crowdli\n",
      "\n",
      "Vanessa Von der Muhll – Head of Communications ... - Linkedin\n",
      "https://ch.linkedin.com › vanessavondermuhll\n",
      "Genf, Genf, Schweiz · Head of Communications and Engagement · ISO - International Organization for Standardization\n",
      "Fifteen years' experience (largely internationally) in the field of communications including strategy, marketing, brand, web, social media, press, ...\n",
      "\n",
      "--------------------------------------------------\n",
      "Jens Wiesenhütter – Head Communications Switzerland https://ch.linkedin.com › jens-wiesen... · Translate page Sankt Gallen, Schweiz · Head Communications Switzerland · Helvetia Versicherungen Schweiz Creative communication manager experience passion strategy, social media, databased storytelling, digital marketing, content marketing, ... Missing: Crowdli | Must include: Crowdli Vanessa Von Muhll – Head Communications ... - Linkedin https://ch.linkedin.com › vanessavondermuhll Genf, Genf, Schweiz · Head Communications Engagement · ISO - International Organization Standardization Fifteen years' experience (largely internationally) field communications including strategy, marketing, brand, web, social media, press, ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Jens Wiesenhütter\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n – Head Communications \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Switzerland\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n https://ch.linkedin.com › jens-wiesen... · Translate page \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Sankt Gallen\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n, \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Schweiz\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n · Head Communications \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Switzerland\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n · \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Helvetia Versicherungen Schweiz Creative\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n communication manager experience passion strategy, social media, databased storytelling, digital marketing, content marketing, ... Missing: Crowdli | Must include: \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Crowdli Vanessa Von Muhll – Head Communications\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n ... - Linkedin https://ch.linkedin.com \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    ›\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n vanessavondermuhll \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Genf\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n, \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Genf\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n, \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Schweiz\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n · Head Communications Engagement · \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    ISO - International Organization Standardization\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Fifteen years'\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n experience (largely internationally) field communications including strategy, marketing, brand, web, social media, press, ...</div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Jens Wiesenhütter\n",
      "Sankt Gallen\n",
      "Crowdli Vanessa Von Muhll – Head Communications\n",
      "›\n",
      "Genf\n",
      "Genf\n",
      "--------------------------------------------------\n",
      "Jens Wiesenhütter\n"
     ]
    }
   ],
   "source": [
    "check = find_replacement_contact(random_slice)\n",
    "person = clean_page(check)\n",
    "print('-'*50)\n",
    "print(person)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This process seems to be fairly consistent, but the NER model is not consistent. I will stick with this for now."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating rules for creating emails"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kpmg.com\n"
     ]
    }
   ],
   "source": [
    "# find Name, Vorname, and email from head of communications\n",
    "email_domain = random_slice[['Email']].iloc[0][0].split('@')[1]\n",
    "print(email_domain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lukas Marty\n"
     ]
    }
   ],
   "source": [
    "#find email address convention\n",
    "current_email = random_slice[['Email']].iloc[0][0]\n",
    "addressee = random_slice[['Vorname', 'Name']].iloc[0].values.tolist()\n",
    "addressee = ' '.join(addressee)\n",
    "print(addressee)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{196: 'Ae', 214: 'Oe', 220: 'Ue', 228: 'ae', 246: 'oe', 252: 'ue'}\n"
     ]
    }
   ],
   "source": [
    "#import common umlauts\n",
    "import unidecode\n",
    "f = open('Data/umlautDictionary.json')\n",
    "umlautDictionary = json.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "umap = {ord(key): val for key, val in umlautDictionary.items()}\n",
    "print(umap)\n",
    "\n",
    "#email address creator\n",
    "def check_format(random_slice):\n",
    "    first_name = random_slice[['Vorname']].iloc[0][0].lower().translate(umap)\n",
    "    first_name = unidecode.unidecode(first_name)\n",
    "    last_name = random_slice[['Name']].iloc[0][0].lower().translate(umap)\n",
    "    last_name = unidecode.unidecode(last_name)\n",
    "    last_name = last_name.replace(\"'\", \"\")\n",
    "    email = random_slice[['Email']].iloc[0][0]\n",
    "    domain = random_slice[['Email']].iloc[0][0].split('@')[1]\n",
    "    print(first_name, last_name, email)\n",
    "    if len(last_name.split(' ')) > 1:\n",
    "        print(last_name.split(' ')[0], last_name.split(' ')[1])\n",
    "        if last_name.split(' ')[0] in email or last_name.split(' ')[1] in email:\n",
    "            print(\"Email format is correct\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Email format is incorrect\")\n",
    "            return False\n",
    "    if first_name not in email or last_name not in email:\n",
    "        print(\"This is a specific email format, double-checking...\")\n",
    "        if 'mail' in email or 'info' in email:\n",
    "            print(\"this is the genereric info email, use this\")\n",
    "            return email\n",
    "    format1 = first_name[0] + last_name + '@' + domain\n",
    "    expression1 = \"first_name[0] + last_name + '@' + domain\"\n",
    "    format2 = first_name + last_name[0] + '@' + domain\n",
    "    expression2 = \"first_name + last_name[0] + '@' + domain\"\n",
    "    format_3 = first_name + last_name + '@' + domain\n",
    "    expression_3 = \"first_name + last_name + '@' + domain\"\n",
    "    format_4 = first_name + '.' + last_name + '@' + domain\n",
    "    expression_4 = \"first_name + '.' + last_name + '@' + domain\"\n",
    "    format_5 = first_name + '_' + last_name + '@' + domain\n",
    "    expression_5 = \"first_name + '_' + last_name + '@' + domain\"\n",
    "    format_6 = first_name + '-' + last_name + '@' + domain\n",
    "    expression_6 = \"first_name + '-' + last_name + '@' + domain\"\n",
    "    format_7 = last_name + '.' + first_name + '@' + domain\n",
    "    expression_7 = \"last_name + '.' + first_name + '@' + domain\"\n",
    "    format_8 = last_name + '_' + first_name + '@' + domain\n",
    "    expression_8 = \"last_name + '_' + first_name + '@' + domain\"\n",
    "    format_9 = last_name + '-' + first_name + '@' + domain\n",
    "    expression_9 = \"last_name + '-' + first_name + '@' + domain\"\n",
    "    format_10 = last_name.split(' ')[0] + first_name[0] + '@' + domain\n",
    "    expression_10 = \"last_name.split(' ')[0] + first_name[0] + '@' + domain\"\n",
    "    format_11 = last_name.split(' ')[0] + first_name + '@' + domain\n",
    "    expression_11 = \"last_name.split(' ')[0] + first_name + '@' + domain\"\n",
    "    format_12 = last_name.split(' ')[0][0] + first_name + '@' + domain\n",
    "    expression_12 = \"last_name.split(' ')[0][0] + first_name + '@' + domain\"\n",
    "    format_13 = first_name + '.' + last_name.split(' ')[0] + '@' + domain\n",
    "    expression_13 = \"first_name + '.' + last_name.split(' ')[0] + '@' + domain\"\n",
    "    format_14 = first_name + '_' + last_name.split(' ')[0] + '@' + domain\n",
    "    expression_14 = \"first_name + '_' + last_name.split(' ')[0] + '@' + domain\"\n",
    "    format_15 = first_name + '-' + last_name.split(' ')[0] + '@' + domain\n",
    "    expression_15 = \"first_name + '-' + last_name.split(' ')[0] + '@' + domain\"\n",
    "    format_16 = last_name + first_name + '@' + domain\n",
    "    expression_16 = \"last_name + first_name + '@' + domain\"\n",
    "    format_17 = first_name[0] + '.' + last_name + '@' + domain\n",
    "    expression_17 = \"first_name[0] + '.' + last_name + '@' + domain\"\n",
    "    format_18 = first_name + last_name.split('-')[0] + '@' + domain\n",
    "    expression_18 = \"first_name + last_name.split('-')[0] + '@' + domain\"\n",
    "    format_19 = first_name + last_name.split('_')[0] + '@' + domain\n",
    "    expression_19 = \"first_name + last_name.split('_')[0] + '@' + domain\"\n",
    "    format_20 = first_name + \".\" + last_name.split('-')[0] + '@' + domain\n",
    "    expression_20 = \"first_name + '.' + last_name.split('-')[0] + '@' + domain\"\n",
    "    format_21 = first_name + \"_\" + last_name.split('-')[0] + '@' + domain\n",
    "    expression_21 = \"first_name + '_' + last_name.split('-')[0] + '@' + domain\"\n",
    "    format_22 = last_name + first_name[0] + '@' + domain\n",
    "    expression_22 = \"last_name + first_name[0] + '@' + domain\"\n",
    "    format_23 = last_name + \".\" + first_name[0] + '@' + domain\n",
    "    expression_23 = \"last_name + '.' + first_name[0] + '@' + domain\"\n",
    "    format_24 = last_name + \"_\" + first_name[0] + '@' + domain\n",
    "    expression_24 = \"last_name + '_' + first_name[0] + '@' + domain\"\n",
    "    format_25 = last_name + first_name + '@' + domain\n",
    "    expression_25 = \"last_name + first_name + '@' + domain\"\n",
    "    format_26 = first_name[0] + '.' + last_name[0] + '@' + domain\n",
    "    expression_26 = \"first_name[0] + '.' + last_name[0] + '@' + domain\"\n",
    "    format_27 = first_name[0] + '_' + last_name[0] + '@' + domain\n",
    "    expression_27 = \"first_name[0] + '_' + last_name[0] + '@' + domain\"\n",
    "    format_28 = last_name[0] + first_name[0] + '@' + domain\n",
    "    expression_28 = \"last_name[0] + first_name[0] + '@' + domain\"\n",
    "    format_29 = last_name[0] + '.' + first_name[0] + '@' + domain\n",
    "    expression_29 = \"last_name[0] + '.' + first_name[0] + '@' + domain\"\n",
    "    format_30 = last_name[0] + '_' + first_name[0] + '@' + domain\n",
    "    expression_30 = \"last_name[0] + '_' + first_name[0] + '@' + domain\"\n",
    "    format_31 = first_name[0] +  last_name[0] + '@' + domain\n",
    "    expression_31 = \"first_name[0] +  last_name[0] + '@' + domain\"\n",
    "\n",
    "\n",
    "    format_list = [format1, format2, format_3, format_4, format_5, format_6, format_7, format_8, format_9, format_10, format_11, format_12, format_13, format_14, format_15, format_16, format_17, format_18, format_19, format_20, format_21, format_22, format_23, format_24, format_25, format_26, format_27, format_28, format_29, format_30, format_31]\n",
    "    expression_list = [expression1, expression2, expression_3, expression_4, expression_5, expression_6, expression_7, expression_8, expression_9, expression_10, expression_11, expression_12, expression_13, expression_14, expression_15, expression_16, expression_17, expression_18, expression_19, expression_20, expression_21, expression_22, expression_23, expression_24, expression_25, expression_26, expression_27, expression_28, expression_29, expression_30, expression_31]\n",
    "\n",
    "    print(\"-\"*100)\n",
    "    for format in format_list:\n",
    "        print(\"-\"*100)\n",
    "        print(f\"Checking {format}\")\n",
    "        if format == email:\n",
    "            print(f\"The email format is {expression_list[format_list.index(format)]}\")\n",
    "            return expression_list[format_list.index(format)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name Vorname             Firma                 Email  Is_Valid\n",
      "349  Pandolfo    Vito  CSS Versicherung  vito.pandolfo@css.ch         1\n",
      "--------------------------------\n",
      "vito pandolfo vito.pandolfo@css.ch\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checking vpandolfo@css.ch\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checking vitop@css.ch\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checking vitopandolfo@css.ch\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checking vito.pandolfo@css.ch\n",
      "The email format is first_name + '.' + last_name + '@' + domain\n",
      "first_name + '.' + last_name + '@' + domain\n"
     ]
    }
   ],
   "source": [
    "random_slice = df.sample(n=1)\n",
    "print(random_slice)\n",
    "print(\"--------------------------------\")\n",
    "checker = check_format(random_slice)\n",
    "print(checker)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This method is very unwieldly and I would like to find a better way to do this. However, it fits the purposes of this project. I will use it for now and if time allows I will try a more programmatic approach."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating rules for umlauts\n",
    "\n",
    "German umlauts are not allowed in the email format. I will create a list of umlauts and their replacements. Normal utf-8 normalisers do not follow the rules for german and are not suitable for this purpose."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "umlautDictionary = {u'Ä': 'Ae',\n",
    "                    u'Ö': 'Oe',\n",
    "                    u'Ü': 'Ue',\n",
    "                    u'ä': 'ae',\n",
    "                    u'ö': 'oe',\n",
    "                    u'ü': 'ue'\n",
    "                    }\n",
    "with open('Data/umlautDictionary.json', 'w') as fp:\n",
    "    json.dump(umlautDictionary, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Putting it all together\n",
    "Now to construct the full workflow into a class with methods."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as notebook_tqdm\n",
    "import time\n",
    "\n",
    "os.environ['WDM_LOG'] = '0'\n",
    "os.environ['WDM_LOG_LEVEL'] = '0'\n",
    "\n",
    "import spacy\n",
    "import unidecode\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#------------ stopword collection----------#\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords_en = en.Defaults.stop_words\n",
    "de = spacy.load('de_core_news_lg')\n",
    "stopwords_de = de.Defaults.stop_words\n",
    "stopwords = stopwords_en.union(stopwords_de)\n",
    "\n",
    "#------------ load NER model----------#\n",
    "ner = spacy.load('en_core_web_lg')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "class ReplaceContacts():\n",
    "    def __init__(self):\n",
    "        self.service = Service(executable_path=ChromeDriverManager().install())\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument(\"--headless\")\n",
    "        self.chrome_options.add_argument(\"--log-level = 3\")\n",
    "        workdir = 'D:\\HSLU_Projects\\Thesis'\n",
    "        if os.getcwd() != workdir:\n",
    "            os.chdir(workdir)\n",
    "        else:\n",
    "            pass\n",
    "        f = open(r'Data/common_acronyms.json')\n",
    "        self.acronyms = json.load(f)\n",
    "        f.close()\n",
    "        f = open('Data/umlautDictionary.json')\n",
    "        umlautDictionary = json.load(f)\n",
    "        f.close()\n",
    "        self.umap = {ord(key): val for key, val in umlautDictionary.items()}\n",
    "        self.ner_model = spacy.load('en_core_web_lg')\n",
    "\n",
    "\n",
    "    #placeholder function to load contacts, will be replaced by a function that loads the contacts the returned data of the other class\n",
    "    def get_contacts(self):\n",
    "        cnx = sqlite3.connect(r\"D:\\HSLU_projects\\Thesis\\Data\\Contacts.db\")\n",
    "        df = pd.read_sql_query('SELECT * FROM Contacts', cnx)\n",
    "        cnx.close()\n",
    "        self.df = df\n",
    "\n",
    "    # function to clean up text\n",
    "    def clean_text(self, page):\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        cleanup = soup.get_text().strip()\n",
    "        jumble = cleanup.split()\n",
    "        cleaned = ' '.join(jumble).strip()\n",
    "        finish = []\n",
    "        for word in cleaned.split():\n",
    "         if word not in stopwords:\n",
    "            finish.append(word)\n",
    "        final = ' '.join(finish)\n",
    "        return final\n",
    "\n",
    "    #function to find the contact name\n",
    "    def contact_person(self, page):\n",
    "        tagged_page = self.ner_model(page)\n",
    "        persons = []\n",
    "        for ent in tagged_page.ents:\n",
    "            if ent.label_ == 'PERSON':\n",
    "                persons.append(ent.text)\n",
    "        person = persons[0]\n",
    "        if ' - ' in person:\n",
    "            person = person.split(' - ')[0]\n",
    "        return person\n",
    "\n",
    "    #function to find the correct email address format\n",
    "    def create_email_rules(self, random_slice):\n",
    "        umap = self.umap\n",
    "        first_name = random_slice[['Vorname']].iloc[0][0].lower().translate(umap)\n",
    "        first_name = unidecode.unidecode(first_name)\n",
    "        last_name = random_slice[['Name']].iloc[0][0].lower().translate(umap)\n",
    "        last_name = unidecode.unidecode(last_name)\n",
    "        last_name = last_name.replace(\"'\", \"\")\n",
    "        email = random_slice[['Email']].iloc[0][0]\n",
    "        domain = random_slice[['Email']].iloc[0][0].split('@')[1]\n",
    "        if len(last_name.split(' ')) > 1:\n",
    "            print(last_name.split(' ')[0], last_name.split(' ')[1])\n",
    "            if last_name.split(' ')[0] in email or last_name.split(' ')[1] in email:\n",
    "                print(\"Email format is correct\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Email format is incorrect\")\n",
    "                return False\n",
    "        if first_name not in email or last_name not in email:\n",
    "            print(\"This is a specific email format, double-checking...\")\n",
    "            if 'mail' in email or 'info' in email:\n",
    "                print(\"this is the genereric info email, use this\")\n",
    "                return email\n",
    "        format1 = first_name[0] + last_name + '@' + domain\n",
    "        expression1 = \"first_name[0] + last_name + '@' + domain\"\n",
    "        format2 = first_name + last_name[0] + '@' + domain\n",
    "        expression2 = \"first_name + last_name[0] + '@' + domain\"\n",
    "        format_3 = first_name + last_name + '@' + domain\n",
    "        expression_3 = \"first_name + last_name + '@' + domain\"\n",
    "        format_4 = first_name + '.' + last_name + '@' + domain\n",
    "        expression_4 = \"first_name + '.' + last_name + '@' + domain\"\n",
    "        format_5 = first_name + '_' + last_name + '@' + domain\n",
    "        expression_5 = \"first_name + '_' + last_name + '@' + domain\"\n",
    "        format_6 = first_name + '-' + last_name + '@' + domain\n",
    "        expression_6 = \"first_name + '-' + last_name + '@' + domain\"\n",
    "        format_7 = last_name + '.' + first_name + '@' + domain\n",
    "        expression_7 = \"last_name + '.' + first_name + '@' + domain\"\n",
    "        format_8 = last_name + '_' + first_name + '@' + domain\n",
    "        expression_8 = \"last_name + '_' + first_name + '@' + domain\"\n",
    "        format_9 = last_name + '-' + first_name + '@' + domain\n",
    "        expression_9 = \"last_name + '-' + first_name + '@' + domain\"\n",
    "        format_10 = last_name.split(' ')[0] + first_name[0] + '@' + domain\n",
    "        expression_10 = \"last_name.split(' ')[0] + first_name[0] + '@' + domain\"\n",
    "        format_11 = last_name.split(' ')[0] + first_name + '@' + domain\n",
    "        expression_11 = \"last_name.split(' ')[0] + first_name + '@' + domain\"\n",
    "        format_12 = last_name.split(' ')[0][0] + first_name + '@' + domain\n",
    "        expression_12 = \"last_name.split(' ')[0][0] + first_name + '@' + domain\"\n",
    "        format_13 = first_name + '.' + last_name.split(' ')[0] + '@' + domain\n",
    "        expression_13 = \"first_name + '.' + last_name.split(' ')[0] + '@' + domain\"\n",
    "        format_14 = first_name + '_' + last_name.split(' ')[0] + '@' + domain\n",
    "        expression_14 = \"first_name + '_' + last_name.split(' ')[0] + '@' + domain\"\n",
    "        format_15 = first_name + '-' + last_name.split(' ')[0] + '@' + domain\n",
    "        expression_15 = \"first_name + '-' + last_name.split(' ')[0] + '@' + domain\"\n",
    "        format_16 = last_name + first_name + '@' + domain\n",
    "        expression_16 = \"last_name + first_name + '@' + domain\"\n",
    "        format_17 = first_name[0] + '.' + last_name + '@' + domain\n",
    "        expression_17 = \"first_name[0] + '.' + last_name + '@' + domain\"\n",
    "        format_18 = first_name + last_name.split('-')[0] + '@' + domain\n",
    "        expression_18 = \"first_name + last_name.split('-')[0] + '@' + domain\"\n",
    "        format_19 = first_name + last_name.split('_')[0] + '@' + domain\n",
    "        expression_19 = \"first_name + last_name.split('_')[0] + '@' + domain\"\n",
    "        format_20 = first_name + \".\" + last_name.split('-')[0] + '@' + domain\n",
    "        expression_20 = \"first_name + '.' + last_name.split('-')[0] + '@' + domain\"\n",
    "        format_21 = first_name + \"_\" + last_name.split('-')[0] + '@' + domain\n",
    "        expression_21 = \"first_name + '_' + last_name.split('-')[0] + '@' + domain\"\n",
    "        format_22 = last_name + first_name[0] + '@' + domain\n",
    "        expression_22 = \"last_name + first_name[0] + '@' + domain\"\n",
    "        format_23 = last_name + \".\" + first_name[0] + '@' + domain\n",
    "        expression_23 = \"last_name + '.' + first_name[0] + '@' + domain\"\n",
    "        format_24 = last_name + \"_\" + first_name[0] + '@' + domain\n",
    "        expression_24 = \"last_name + '_' + first_name[0] + '@' + domain\"\n",
    "        format_25 = last_name + first_name + '@' + domain\n",
    "        expression_25 = \"last_name + first_name + '@' + domain\"\n",
    "        format_26 = first_name[0] + '.' + last_name[0] + '@' + domain\n",
    "        expression_26 = \"first_name[0] + '.' + last_name[0] + '@' + domain\"\n",
    "        format_27 = first_name[0] + '_' + last_name[0] + '@' + domain\n",
    "        expression_27 = \"first_name[0] + '_' + last_name[0] + '@' + domain\"\n",
    "        format_28 = last_name[0] + first_name[0] + '@' + domain\n",
    "        expression_28 = \"last_name[0] + first_name[0] + '@' + domain\"\n",
    "        format_29 = last_name[0] + '.' + first_name[0] + '@' + domain\n",
    "        expression_29 = \"last_name[0] + '.' + first_name[0] + '@' + domain\"\n",
    "        format_30 = last_name[0] + '_' + first_name[0] + '@' + domain\n",
    "        expression_30 = \"last_name[0] + '_' + first_name[0] + '@' + domain\"\n",
    "        format_31 = first_name[0] +  last_name[0] + '@' + domain\n",
    "        expression_31 = \"first_name[0] +  last_name[0] + '@' + domain\"\n",
    "\n",
    "\n",
    "        format_list = [format1, format2, format_3, format_4, format_5, format_6, format_7, format_8, format_9, format_10, format_11, format_12, format_13, format_14, format_15, format_16, format_17, format_18, format_19, format_20, format_21, format_22, format_23, format_24, format_25, format_26, format_27, format_28, format_29, format_30, format_31]\n",
    "        expression_list = [expression1, expression2, expression_3, expression_4, expression_5, expression_6, expression_7, expression_8, expression_9, expression_10, expression_11, expression_12, expression_13, expression_14, expression_15, expression_16, expression_17, expression_18, expression_19, expression_20, expression_21, expression_22, expression_23, expression_24, expression_25, expression_26, expression_27, expression_28, expression_29, expression_30, expression_31]\n",
    "        for format in format_list:\n",
    "            if format == email:\n",
    "                return expression_list[format_list.index(format)]\n",
    "\n",
    "    # function to find new contact - currently defaulting to head of communications\n",
    "    def find_new_contact(self, random_slice):\n",
    "        driver = webdriver.Chrome(service=self.service, options=self.chrome_options)\n",
    "        driver.implicitly_wait(25)\n",
    "        driver.get(\"https://www.google.com/\")\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                        \"/html/body/div[2]/div[2]/div[3]/span/div/div/div/div[3]/button[2]\"))).click()\n",
    "        except:\n",
    "            pass\n",
    "        m = driver.find_element(by=By.NAME, value='q')\n",
    "        m.send_keys(random_slice.iloc[0]['Firma'] + \" Head of Communication Switzerland\")\n",
    "        m.send_keys(Keys.RETURN)\n",
    "\n",
    "        first_page = page = driver.find_element(By .TAG_NAME, \"body\").text\n",
    "        if \"featured snippet\" in first_page:\n",
    "            print(\"Featured snippet found, extract team from here\")\n",
    "            try:\n",
    "                WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                           '//*[@id=\"rso\"]/div[1]/block-component/div/div[1]/div/div/div/div/div[1]/div/div/div/div/div/div[2]/div/div/div[1]'))).click()\n",
    "                page = driver.find_element(By .TAG_NAME, \"body\").text\n",
    "            except:\n",
    "                print(\"Can't find the element\")\n",
    "                pass\n",
    "        else:\n",
    "            print(\"not found, going to first link\")\n",
    "\n",
    "            try:\n",
    "                check_for_linkedin = driver.find_element(By.XPATH, '//*[@id=\"rso\"]/div[1]').text\n",
    "                print(check_for_linkedin)\n",
    "                if \"https://ch.linkedin.com\" in check_for_linkedin:\n",
    "                    print(\"LinkedIn found, extract info from here\")\n",
    "                    page = check_for_linkedin\n",
    "                else:\n",
    "                    print(\"LinkedIn not found, going to first link\")\n",
    "                    WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                            '//*[@id=\"rso\"]/div[1]/div/div[1]/div/a/h3'))).click()\n",
    "                    time.sleep(5)\n",
    "                    if driver.findElement( By.XPATH, '/html/body/div[4]/div/div/div[2]/div[1]/button' ).size() != 0:\n",
    "                        WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                            '/html/body/div[4]/div/div/div[2]/div[1]/button'))).click()\n",
    "                        page = driver.find_element(By .TAG_NAME, \"body\").text\n",
    "                    else:\n",
    "                        page = driver.find_element(By .TAG_NAME, \"body\").text\n",
    "            except:\n",
    "                print(\"Can't find the element\")\n",
    "                pass\n",
    "\n",
    "        driver.close()\n",
    "        return page\n",
    "\n",
    "    #function to build email from found contact\n",
    "    def create_email(self, random_slice, person, email_format):\n",
    "        first_name = person.split(\" \")[0]\n",
    "        if len(person.split(\" \")) == 2:\n",
    "            last_name = person.split(\" \")[1]\n",
    "        else:\n",
    "            last_name = (' '.join(person.split(\" \")) - first_name)\n",
    "        domain = random_slice[['Email']].iloc[0][0].split('@')[1]\n",
    "        email = eval(email_format)\n",
    "        return email\n",
    "\n",
    "    #function to find and replace invalid contact\n",
    "    def find_and_replace(self, df):\n",
    "        random_slice = df.sample(n=1)\n",
    "        print(\"checking for new contact for {}\".format(random_slice.iloc[0]['Firma']))\n",
    "        page = self.find_new_contact(random_slice)\n",
    "        cleaned_page = self.clean_text(page)\n",
    "        person = self.contact_person(cleaned_page)\n",
    "        email_format = self.create_email_rules(random_slice)\n",
    "        Email = self.create_email(random_slice, person, email_format)\n",
    "        Vorname = person.split(\" \")[0]\n",
    "        if len(person.split(\" \")) == 2:\n",
    "            Name = person.split(\" \")[1]\n",
    "        else:\n",
    "            Name = (' '.join(person.split(\" \")) - Vorname)\n",
    "        Firma = random_slice[['Firma']].iloc[0][0]\n",
    "        print(\"the new contact for {} is {} {} with email {}\".format(Firma, Vorname, Name, Email))\n",
    "        return Name, Vorname, Email, Firma\n",
    "\n",
    "    #function to iterate over all wrong contacts and replace with new contact\n",
    "    def full_contact_replacement(self, df):\n",
    "        wrong_contacts = df[df['Is_Valid'] == 0]\n",
    "        for idx, row in wrong_contacts.iterrows():\n",
    "            Name, Vorname, Email, Firma = self.find_and_replace(df = wrong_contacts)\n",
    "            df.loc[idx, 'Name'] = Name\n",
    "            df.loc[idx, 'Vorname'] = Vorname\n",
    "            df.loc[idx, 'Email'] = Email\n",
    "            df.loc[idx, 'Firma'] = Firma\n",
    "            df.loc[idx, 'Is_Valid'] = 1\n",
    "        print(\"{} wrong contacts replaced\".format(len(wrong_contacts)))\n",
    "        confirmation = input(\"Do you want to save the new dataframe? (y/n)\")\n",
    "        if confirmation == 'y':\n",
    "            df = df.combine_first(wrong_contacts)\n",
    "        else:\n",
    "            print(\"Contact replacement aborted\")\n",
    "            pass\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for new contact for Pilatus-Bahnen AG\n",
      "not found, going to first link\n",
      "Marco Thali – Leiter Marketing - PILATUS-BAHNEN AG\n",
      "https://ch.linkedin.com › ...\n",
      "· Translate this page\n",
      "Luzern, Luzern, Schweiz · Leiter Marketing - Communications · PILATUS-BAHNEN AG\n",
      "PILATUS-BAHNEN AG · athleticum Sportmarkets AG Grafik. Head Marketing Communication · LK International AG Grafik. Marketing Coordinator · Catrade Sportmarketing AG ...\n",
      "Missing: Switzerland | Must include: Switzerland\n",
      "LinkedIn found, extract info from here\n",
      "the new contact for Pilatus-Bahnen AG is Marco Thali with email Marco.Thali@pilatus.ch\n"
     ]
    },
    {
     "data": {
      "text/plain": "('Marco.Thali@pilatus.ch', 'Marco', 'Thali', 'Pilatus-Bahnen AG')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ReplaceContacts()\n",
    "test.get_contacts()\n",
    "test.find_and_replace(test.df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double-check contact_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "\n",
    "os.environ['WDM_LOG'] = '0'\n",
    "os.environ['WDM_LOG_LEVEL'] = '0'\n",
    "\n",
    "from fuzzysearch import find_near_matches\n",
    "from thefuzz import process, fuzz\n",
    "\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# ------------ stopword collection----------#\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords_en = en.Defaults.stop_words\n",
    "de = spacy.load('de_core_news_lg')\n",
    "stopwords_de = de.Defaults.stop_words\n",
    "stopwords = stopwords_en.union(stopwords_de)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "class Check_Contacts:\n",
    "    def __init__(self):\n",
    "        self.service = Service(executable_path=ChromeDriverManager().install())\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument(\"--headless\")\n",
    "        self.chrome_options.add_argument(\"--log-level = 3\")\n",
    "        workdir = 'D:\\HSLU_Projects\\Thesis'\n",
    "        if os.getcwd() != workdir:\n",
    "            os.chdir(workdir)\n",
    "        else:\n",
    "            pass\n",
    "        f = open(r'Data/common_acronyms.json')\n",
    "        self.acronyms = json.load(f)\n",
    "\n",
    "    # function to connect to sqlite database\n",
    "    def get_contacts(self):\n",
    "        cnx = sqlite3.connect(r\"D:\\HSLU_projects\\Thesis\\Data\\Contacts.db\")\n",
    "        df = pd.read_sql_query(\"SELECT * FROM Contacts\", cnx)\n",
    "        cnx.close()\n",
    "        return df\n",
    "\n",
    "    # function to tag loaded web elements\n",
    "    def create_tags(self, text):\n",
    "        ner_model = spacy.load(r\"./Model/output/model-last\")\n",
    "        nlp = ner_model(text)\n",
    "        return nlp.ents\n",
    "\n",
    "    # function to clean html into text\n",
    "    def clean_text(self, web_element):\n",
    "        cleanup = web_element.text.strip()\n",
    "        jumble = cleanup.split()\n",
    "        cleaned = ' '.join(jumble).strip()\n",
    "        return cleaned\n",
    "\n",
    "    # function to return list of workplaces\n",
    "    def list_of_firma(self, tuple):\n",
    "        workplaces = []\n",
    "        for i in tuple:\n",
    "            if i.label_ == 'Firma':\n",
    "                workplaces.append(i.text)\n",
    "        return workplaces\n",
    "\n",
    "    # function to remove stopwords\n",
    "    def cleanup(self, text):\n",
    "        finish = []\n",
    "        try:\n",
    "            for token in text.split():\n",
    "                if token.lower() not in stopwords:  # checking whether the word is not\n",
    "                    finish.append(token)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        final = ' '.join(finish)\n",
    "        return final\n",
    "\n",
    "    # function to find a common abbreviation\n",
    "    def acronym_checker(self, text):\n",
    "        if text in self.acronyms.keys():\n",
    "            return self.acronyms[text]\n",
    "        else:\n",
    "            return \"No\"\n",
    "\n",
    "    # function to load contact table\n",
    "    def load_contacts(self):\n",
    "        cnx = sqlite3.connect(r\"D:\\HSLU_projects\\Thesis\\Data\\Contacts.db\")\n",
    "        df = pd.read_sql_query(\"SELECT * FROM Contacts\", cnx)\n",
    "        cnx.close()\n",
    "        self.df = df\n",
    "\n",
    "    # function to check the link of a email google search\n",
    "    def check_employment(self, df_slice):\n",
    "        Top = None\n",
    "        Bottom = None\n",
    "        Missing = None\n",
    "\n",
    "        driver = webdriver.Chrome(service=self.service, options=self.chrome_options)\n",
    "        driver.implicitly_wait(50)\n",
    "        driver.get(\"https://www.google.com/\")\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(expected_conditions.element_to_be_clickable((By.XPATH,\n",
    "                                                                                        \"/html/body/div[2]/div[2]/div[3]/span/div/div/div/div[3]/button[2]\"))).click()\n",
    "        except:\n",
    "            pass\n",
    "        m = driver.find_element(by=By.NAME, value=\"q\")\n",
    "        m = driver.find_element(by=By.NAME, value='q')\n",
    "        if \"info\" not in df_slice['Email']:\n",
    "            m.send_keys(df_slice['Email'])\n",
    "        else:\n",
    "            m.send_keys(df_slice['Vorname'] + ' ' + df_slice['Name'] + ' ' + df_slice['Firma'])\n",
    "        m.send_keys(Keys.ENTER)\n",
    "        time.sleep(3)\n",
    "        web_element = driver.find_element(by=By.XPATH, value='//*[@id=\"rso\"]/div[1]/div/div[1]')\n",
    "        Top = self.clean_text(web_element)\n",
    "        if Top is not None:\n",
    "            Top = self.cleanup(Top)\n",
    "        try:\n",
    "            Bottom = self.clean_text(web_element=driver.find_element(by=By.XPATH, value='//*[@id=\"rso\"]/div[1]/div/div[2]').text)\n",
    "            Bottom = self.cleanup(Bottom)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            Missing = self.clean_text(web_element=driver.find_element(by=By.XPATH, value='//*[@id=\"rso\"]/div[1]/div/div[3]').text)\n",
    "            Missing = self.cleanup(Missing)\n",
    "        except:\n",
    "            pass\n",
    "        driver.close()\n",
    "        if Missing is not None and 'missing' in Missing:\n",
    "            return {\"Top Line\": Top,\n",
    "                    \"Middle Line\": Bottom,\n",
    "                    'Missing element': Missing}\n",
    "        else:\n",
    "            return {\"Top Line\": Top,\n",
    "                    \"Middle Line\": Bottom,\n",
    "                    \"Addendum\": Missing}\n",
    "\n",
    "    # function to check if email is valid\n",
    "    def validation(self, n=5):\n",
    "        sample_check = self.df.sample(n=n)\n",
    "        with tqdm(total=n) as pbar:\n",
    "            for idx, row in sample_check.iterrows():\n",
    "                print(f\"Checking now for {row[1]} {row[0]} at {row[2]} with {row[3]}\")\n",
    "                print(row)\n",
    "                print(\"-----------------------------------------------\")\n",
    "                validation_online = self.check_employment(row)\n",
    "                if 'Missing' in validation_online.values() or \"It looks like there aren't many great matches for your search\" in validation_online.values():\n",
    "                    print(\n",
    "                        f\"{row['Vorname']} {row['Name']}'s' email {row['Email']} does not appear in the first search. They may no longer work at {row['Firma']}\")\n",
    "                    continue\n",
    "                check_work = find_near_matches(row[2].split()[0],\n",
    "                                               validation_online['Top Line'],\n",
    "                                               max_l_dist=1)\n",
    "                print(check_work)\n",
    "                acronym = self.acronym_checker(row[\"Firma\"])\n",
    "                check_work_acronym = None\n",
    "                if acronym != \"No\":\n",
    "                    check_work_acronym = find_near_matches(acronym,\n",
    "                                                           validation_online['Top Line'],\n",
    "                                                           max_l_dist=1)\n",
    "                    print(check_work_acronym)\n",
    "                Firma_list = []\n",
    "                for i in validation_online.values():\n",
    "                    if i is not None:\n",
    "                        tags = self.create_tags(i)\n",
    "                        Firma_list.append(self.list_of_firma(tags))\n",
    "                l = [item for sublist in Firma_list for item in sublist]\n",
    "                check_Firma = find_near_matches(row[\"Firma\"].split()[0], l, max_l_dist=1)\n",
    "                print(l)\n",
    "                if len(check_work) != 0 or check_work_acronym != None or len(check_Firma) != 0:\n",
    "                    print(f\"{row[1]} {row[0]} seems to still works at {row[2]}\")\n",
    "                elif len(check_work) != 0 and check_work_acronym != None and len(check_Firma) != 0:\n",
    "                    print(f\"{row[1]} {row[0]} definitely still works at {row[2]}\")\n",
    "                elif len(check_work) == 0 and check_work_acronym is None and len(check_Firma) == 0:\n",
    "                    print(f\"{row[1]} {row[0]} does not work at {row[2]} anymore\")\n",
    "                    row['Is_valid'] = 0\n",
    "                print(\"-----------------------------------------------\")\n",
    "                pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Check_Contacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.load_contacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking now for Gaudenz Zemp-Lüthy at Gewerbeverband Kanton Luzern with zemp@gewerbeverband-lu.ch\n",
      "Name                          Zemp-Lüthy\n",
      "Vorname                          Gaudenz\n",
      "Firma       Gewerbeverband Kanton Luzern\n",
      "Email          zemp@gewerbeverband-lu.ch\n",
      "Is_Valid                               1\n",
      "Name: 515, dtype: object\n",
      "-----------------------------------------------\n",
      "[Match(start=20, end=34, dist=0, matched='Gewerbeverband'), Match(start=152, end=166, dist=0, matched='Gewerbeverband')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:21<05:26, 81.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gewerbeverband Kanton Luzern', 'Luzern Direktor Gewerbeverbandes Kantons Luzern']\n",
      "Gaudenz Zemp-Lüthy seems to still works at Gewerbeverband Kanton Luzern\n",
      "-----------------------------------------------\n",
      "Checking now for Urs Bucher at Adidas Sport GmbH with urs.bucher@adidas.ch\n",
      "Name                      Bucher\n",
      "Vorname                      Urs\n",
      "Firma          Adidas Sport GmbH\n",
      "Email       urs.bucher@adidas.ch\n",
      "Is_Valid                       1\n",
      "Name: 79, dtype: object\n",
      "-----------------------------------------------\n",
      "[Match(start=0, end=6, dist=1, matched='adidas')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:29<01:55, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Urs Bucher seems to still works at Adidas Sport GmbH\n",
      "-----------------------------------------------\n",
      "Checking now for Ralf Bellm at Bettr AG with ralf.bellm@bettrrealestate.ch\n",
      "Name                                Bellm\n",
      "Vorname                              Ralf\n",
      "Firma                            Bettr AG\n",
      "Email       ralf.bellm@bettrrealestate.ch\n",
      "Is_Valid                                1\n",
      "Name: 42, dtype: object\n",
      "-----------------------------------------------\n",
      "[Match(start=30, end=34, dist=1, matched='ettr'), Match(start=156, end=160, dist=1, matched='ettr')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:26<01:33, 46.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Ralf Bellm seems to still works at Bettr AG\n",
      "-----------------------------------------------\n",
      "Checking now for Robert Lüthi at AbbVie AG with robert.luethi@abbvie.com\n",
      "Name                           Lüthi\n",
      "Vorname                       Robert\n",
      "Firma                      AbbVie AG\n",
      "Email       robert.luethi@abbvie.com\n",
      "Is_Valid                           1\n",
      "Name: 288, dtype: object\n",
      "-----------------------------------------------\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:34<00:31, 31.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CFO Advisory Digital Finance ... - Linkedin']\n",
      "Robert Lüthi does not work at AbbVie AG anymore\n",
      "-----------------------------------------------\n",
      "Checking now for Thomas Grimm at Losinger Marazzi AG with th.grimm@losinger-marazzi.ch\n",
      "Name                               Grimm\n",
      "Vorname                           Thomas\n",
      "Firma                Losinger Marazzi AG\n",
      "Email       th.grimm@losinger-marazzi.ch\n",
      "Is_Valid                               1\n",
      "Name: 171, dtype: object\n",
      "-----------------------------------------------\n",
      "[Match(start=21, end=29, dist=0, matched='Losinger'), Match(start=50, end=58, dist=1, matched='losinger'), Match(start=116, end=124, dist=1, matched='losinger'), Match(start=257, end=265, dist=0, matched='Losinger'), Match(start=286, end=294, dist=1, matched='losinger'), Match(start=450, end=458, dist=1, matched='losinger')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:23<00:00, 52.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Losinger Marazzi', 'Losinger Marazzi']\n",
      "Thomas Grimm seems to still works at Losinger Marazzi AG\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test.validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Miscellaneous tests:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "slice = df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'first frame networkers ag'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice.iloc[0, 2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}